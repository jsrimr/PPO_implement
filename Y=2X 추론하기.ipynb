{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  y = 2*x 에서 y는 x그대로 받아오되 x_1만 2배 한 값으로 한다면 weight 는 이런 관계를 배울 수 있을까? -> 잘 안된다\n",
    "#심지어는 그냥 y = 2*x 도 못배우는 것 같다.\n",
    "\n",
    "#인줄 알았는데 활성화함수 relu 에서 leaky_relu 로 바꾸고\n",
    "#weight_decay 적용하니 loss 좀 더 떨어진다. ( 2.0 -> 0.2 수준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5,32)\n",
    "        nn.init.orthogonal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(32,5)\n",
    "        nn.init.orthogonal_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(10000,5)\n",
    "Y = np.copy(X)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.36400361, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.32685117, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.46724646, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.6307137 , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.36540022, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_ = np.zeros_like(X)\n",
    "add_[:,2] = X[:,2]\n",
    "add_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17845863, 0.97520082, 0.72800722, 0.90915476, 0.83586269],\n",
       "       [0.84958619, 0.3599186 , 0.65370235, 0.58966322, 0.68591665],\n",
       "       [0.85410122, 0.71513694, 0.93449292, 0.53928303, 0.65300494],\n",
       "       [0.4822877 , 0.29937474, 1.2614274 , 0.1074775 , 0.10291037],\n",
       "       [0.30233421, 0.09810272, 0.73080044, 0.95463943, 0.16202549]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y+=add_\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17845863, 0.97520082, 0.36400361, 0.90915476, 0.83586269],\n",
       "       [0.84958619, 0.3599186 , 0.32685117, 0.58966322, 0.68591665],\n",
       "       [0.85410122, 0.71513694, 0.46724646, 0.53928303, 0.65300494],\n",
       "       [0.4822877 , 0.29937474, 0.6307137 , 0.1074775 , 0.10291037],\n",
       "       [0.30233421, 0.09810272, 0.36540022, 0.95463943, 0.16202549]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),weight_decay=1e-4)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "len_X = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,X,Y):\n",
    "        self.len = len(X)\n",
    "        self.X =  torch.tensor(X).to(device).float()\n",
    "        self.Y =  torch.tensor(Y).to(device).float()\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.X[index], self.Y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "data_loader = DataLoader(dataset=CustomDataset(X,Y),\n",
    "                         batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5016, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.5074, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.5213, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.5043, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.5096, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.5090, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4854, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.5003, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4923, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4888, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4829, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4978, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4876, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4836, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4765, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4743, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(0.4735, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(7.3139e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.4547e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(5.0803e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(8.1640e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.2078e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(5.5929e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.0763e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.4037e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(9.4084e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.6736e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.2485e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.4120e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.4520e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.9328e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.3006e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(5.1014e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(7.1446e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.0753e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.2750e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.5650e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(5.7094e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(7.1198e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.9176e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.8395e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.2710e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.1024e-05, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(8.0596e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.7737e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.4947e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(8.1579e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(1.8462e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.8539e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(4.9009e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.4341e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(4.9740e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.3571e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(3.8635e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.1533e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(2.6860e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "tensor(6.0621e-06, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-310a6ce5fd2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    for X, Y in data_loader:\n",
    "\n",
    "        pred = model(X).cuda()\n",
    "        actual = Y.cuda()\n",
    "        loss = criterion(pred,actual)\n",
    "\n",
    "        if epoch % 100==0:\n",
    "            print(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4168, 0.7078, 0.8230, 0.4213, 0.9614],\n",
       "        [0.9702, 0.9377, 0.3863, 0.9399, 0.0017],\n",
       "        [0.5469, 0.0616, 0.0147, 0.0157, 0.4727],\n",
       "        [0.4500, 0.6345, 0.1943, 0.0973, 0.4021],\n",
       "        [0.6222, 0.9168, 0.3842, 0.2496, 0.5598]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4168, 0.7078, 1.6461, 0.4213, 0.9614],\n",
       "        [0.9702, 0.9377, 0.7726, 0.9399, 0.0017],\n",
       "        [0.5469, 0.0616, 0.0293, 0.0157, 0.4727],\n",
       "        [0.4500, 0.6345, 0.3885, 0.0973, 0.4021],\n",
       "        [0.6222, 0.9168, 0.7683, 0.2496, 0.5598]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= model(torch.tensor(X[:5]).to(device).float())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(1000000):\n",
    "    batch_idx = np.random.randint(0,len_X,BATCH_SIZE)\n",
    "    \n",
    "    \n",
    "    input_ = torch.tensor(X[batch_idx]).to(device).float() #cuda().float()\n",
    "    pred = model(input_)\n",
    "    \n",
    "    actual = torch.tensor(Y[batch_idx]).to(device).float() #cuda().float()\n",
    "    loss = criterion(pred, actual)\n",
    "    if epoch % 1000 ==0:\n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "    oprimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.tensor(X[:5]).float()\n",
    "pred = model(input_)\n",
    "    \n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.tensor(X[3]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = torch.tensor(X[3]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = F.relu(torch.matmul(model.fc1.weight, outlier))\n",
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = F.leaky_relu(torch.matmul(model.fc1.weight, outlier))\n",
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs([1,2,-3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = model.fc1.weight.data.numpy()\n",
    "abs_weight = np.sum(np.abs(weight))\n",
    "abs_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = np.array([[  74.4057, -151.3229,  -75.9739,  113.4148,  -65.4401],\n",
    "        [ -42.5526,  -51.1015,  -50.8704,  -30.4177,   10.2180],\n",
    "        [ -38.8787,   15.7415,  -40.9943,  -12.2715,   61.9394],\n",
    "        [ -19.8815,   21.4795,  -61.7220,   -9.2153,   14.9094],\n",
    "        [   8.9980,  -31.5722,  -19.2692,    9.3654,  -41.9142],\n",
    "        [  20.1367,   21.2434,   -7.4982,    2.9637,  -21.3430],\n",
    "        [  12.6065,  -24.2188,   36.9866,   -1.7362,   14.9764],\n",
    "        [  30.1145,  -44.4458,  -66.0547,   34.5192,  -63.8786],\n",
    "        [   0.5771,  -62.6937,  -43.6030,   40.8605,  -48.6069],\n",
    "        [  42.3436,  -42.8105,   52.8249, -134.9727,   81.6493],\n",
    "        [ -20.6963,   80.1004, -109.1529, -122.6146,   41.0892],\n",
    "        [   1.2579,   28.9878,   38.6529,  -18.8071,    4.9848],\n",
    "        [  37.7353,  -62.1961,   33.1517,  -77.3900,  -73.8069],\n",
    "        [ -20.3247,   11.7916,   -1.7706,  -26.6897,  -16.4416],\n",
    "        [ -20.9047,  -36.9988,  -39.3248,  -41.9803,   33.7350],\n",
    "        [  -5.6645,  -21.8163,   14.4779,  -24.0611,  -22.0431],\n",
    "        [   9.3259,  -28.2866,  -12.0421,   56.2059,  -16.7891],\n",
    "        [  -4.8567,    2.9125,   10.0901,   31.6878,  -10.5206],\n",
    "        [   4.5169,  -39.2323,   -2.0947,    9.9828,   22.4635],\n",
    "        [-120.1635,  -63.8106,  -98.7930,   12.7172,   12.6185],\n",
    "        [ -60.4427,  -65.7486,  -69.0505,    3.6757,  -59.7096],\n",
    "        [ -25.8382,  -52.3037,   -3.2063,  -32.8781,   -0.1869],\n",
    "        [  48.9795,  -48.2363,   56.8668,  -19.6195,  -81.3323],\n",
    "        [  -3.4295,   -4.9643,   12.1966,   40.4992,  -59.3798],\n",
    "        [ -17.2330,   15.8030,  -25.2491,  -20.8867,  -11.8825],\n",
    "        [  12.2973,  -79.2085,  -18.0856,  -76.5139,  -22.9457],\n",
    "        [   8.6904,   27.3708,  -72.7444,  -59.8228,   30.3907],\n",
    "        [  42.9021,   -0.4155,   26.4400,  -18.3841,   10.4383],\n",
    "        [ -17.6994,   27.0031,  -13.6291,  -36.5837,  -39.6292],\n",
    "        [   9.8818,  -16.3479,   41.0126,  -25.4142,   35.9940],\n",
    "        [ -11.9840,   20.4287,   17.9808,  -11.2879,   -5.8106],\n",
    "        [  -6.8359,  -83.3647,  -15.3483,  -16.4897,  -26.8888]])\n",
    "abs_weight = np.sum(np.abs(before))\n",
    "abs_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.empty(3,5)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.init.orthogonal_(model.fc1.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
